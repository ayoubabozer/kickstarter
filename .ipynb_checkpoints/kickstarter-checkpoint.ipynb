{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from ks-projects-201801.csv - 378,661 projects.\n",
    "dataframe = pd.read_csv('ks-projects-201801.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 378661 entries, 0 to 378660\n",
      "Data columns (total 15 columns):\n",
      "ID                  378661 non-null int64\n",
      "name                378657 non-null object\n",
      "category            378661 non-null object\n",
      "main_category       378661 non-null object\n",
      "currency            378661 non-null object\n",
      "deadline            378661 non-null object\n",
      "goal                378661 non-null float64\n",
      "launched            378661 non-null object\n",
      "pledged             378661 non-null float64\n",
      "state               378661 non-null object\n",
      "backers             378661 non-null int64\n",
      "country             378661 non-null object\n",
      "usd pledged         374864 non-null float64\n",
      "usd_pledged_real    378661 non-null float64\n",
      "usd_goal_real       378661 non-null float64\n",
      "dtypes: float64(5), int64(2), object(8)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# show information and data types of the data attributes.\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 rows from the data frame.\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projects state ratio\n",
    "(dataframe['state'].value_counts()/len(dataframe))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot state distribution.\n",
    "sns.catplot('state',data=dataframe,kind='count', height=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of launched projects per day of week \n",
    "dataframe.groupby([(pd.to_datetime(dataframe.launched).dt.strftime(\"%A\"))]).size().plot(kind='bar',figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total projects per year\n",
    "dataframe.groupby([(pd.to_datetime(dataframe.launched).dt.year)]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.groupby([(pd.to_datetime(dataframe.launched).dt.year)]).size().plot(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will reduce datapoints to get more clean data\n",
    "start_date = '2013-01-01'\n",
    "dataframe = dataframe[dataframe['launched'] >= start_date]\n",
    "dataframe.groupby([(pd.to_datetime(dataframe.launched).dt.year)]).size().plot(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average pledged amount in USD\n",
    "round(dataframe['usd_pledged_real'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average backers\n",
    "int(dataframe['backers'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average projects goal in usd\n",
    "round(dataframe['usd_goal_real'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat map of average backers by country and main_category\n",
    "pivot_table = dataframe.pivot_table(index='main_category', \n",
    "                   columns='country', \n",
    "                   values='backers', \n",
    "                   aggfunc='mean')\n",
    "sns.heatmap(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the prediction purpose, i will filter the data\n",
    "# to have only successful and failed projects.\n",
    "dataframe = dataframe.loc[dataframe['state'].isin(['successful', 'failed'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projects main category ratio\n",
    "(dataframe['main_category'].value_counts()/len(dataframe))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot main category ratio distibution\n",
    "(dataframe['main_category'].value_counts()/len(dataframe)).plot.pie(y='mass', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count projects by country\n",
    "dataframe['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot country distribution\n",
    "sns.catplot('country',data=dataframe, order = dataframe['country'].value_counts().index,kind='count', height=6,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now country/state distribution.\n",
    "sns.catplot(y=\"country\", hue=\"state\", kind=\"count\",edgecolor=\".6\", data=dataframe, order = dataframe['country'].value_counts().index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which columns has null values\n",
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that usd_pledged are the only column that has null values\n",
    "# we will drop this column and so all columns that is known just after project is launched like\n",
    "# pledged, backers, usd_pledged_real\n",
    "# name, ID also are not influcing the machine learning process , so i will delete it as well.\n",
    "dataframe = dataframe.drop(['ID', 'name', 'usd pledged', 'pledged', 'backers', 'usd_pledged_real'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataframe now \n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode string values to integers for the macheine learning purpose\n",
    "countryTransformer = preprocessing.LabelEncoder()\n",
    "currencyTransformer = preprocessing.LabelEncoder()\n",
    "main_categoryTransformer = preprocessing.LabelEncoder()\n",
    "categoryTransformer = preprocessing.LabelEncoder()\n",
    "dataframe['country'] = countryTransformer.fit_transform(dataframe['country'])\n",
    "dataframe['currency'] = currencyTransformer.fit_transform(dataframe['currency'])\n",
    "dataframe['main_category'] = main_categoryTransformer.fit_transform(dataframe['main_category'])\n",
    "dataframe['category'] = categoryTransformer.fit_transform(dataframe['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates to Unix time in nano seconds\n",
    "dataframe[\"launched\"] = pd.to_datetime(dataframe[\"launched\"])\n",
    "dataframe[\"deadline\"] = pd.to_datetime(dataframe[\"deadline\"])\n",
    "dataframe[\"deadline\"] =  dataframe.deadline.values.astype(np.int64)\n",
    "dataframe[\"launched\"] =  dataframe.launched.values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the dataframe without the state column\n",
    "X = dataframe.drop('state', axis=1)\n",
    "# Y is the state column\n",
    "Y = dataframe['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are splitting the data into 80% and 20%\n",
    "# 80% is for the model training X_train, Y_train\n",
    "# 20% is for the model testing X_test, Y_test\n",
    "# we will predict the state of X_test and compare it to the real data Y_test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us check multiplue classification machine learning models\n",
    "\n",
    "\n",
    "# prepare models\n",
    "classifiers = [\n",
    "    DecisionTreeClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GaussianNB()\n",
    "]\n",
    "\n",
    "# evaluate one by one to check who is the most accuracte \n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(clf.__class__.__name__)    \n",
    "    \n",
    "    prediction = clf.predict(X_test)\n",
    "    acc = accuracy_score(Y_test, prediction)\n",
    "    \n",
    "    print(\"Accuracy: {:.2%}\".format(acc))\n",
    "\n",
    "print(\"=\"*30)\n",
    "print('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that GradientBoostingClassifier is the most accurist model\n",
    "# so lets perform fine tuning on the learning_rate attribute of the model\n",
    "learning_rates = [1, 0.7, 0.5, 0.25, 0.1, 0.01]\n",
    "for lrn in learning_rates:\n",
    "    clf = GradientBoostingClassifier(learning_rate=lrn)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"=\"*30)\n",
    "    print(lrn)\n",
    "    prediction = clf.predict(X_test)\n",
    "    acc = accuracy_score(Y_test, prediction)\n",
    "    print(\"Accuracy: {:.2%}\".format(acc))\n",
    "    \n",
    "print(\"=\"*30)\n",
    "print('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the best performance learning rate\n",
    "# in fact, we can get more accuracy if we have more informative data features.\n",
    " \n",
    "clf = GradientBoostingClassifier(learning_rate=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('****Results****')\n",
    "prediction = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, prediction)\n",
    "print(\"Accuracy: {:.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing prediction to true data\n",
    "np.column_stack((prediction,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us see the feature importance order of the predition model.\n",
    "feats = {}\n",
    "for feature, importance in zip(X_train.columns, clf.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Feature-importance'})\n",
    "importances.sort_values(by='Feature-importance').plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now i will add a new feature based on the existing data\n",
    "# dateDiff will be deadline - launched\n",
    "#dataframe[\"project_length\"] = round(abs((dataframe[\"deadline\"] - dataframe[\"launched\"]))/10**9/60/60/24)\n",
    "dataframe[\"project_length\"] = dataframe[\"deadline\"] - dataframe[\"launched\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the dataframe without the state column\n",
    "X = dataframe.drop('state', axis=1)\n",
    "# Y is the state column\n",
    "Y = dataframe['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again split the data to 80% 20%\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are predicting with the new added feature\n",
    "clf = GradientBoostingClassifier(learning_rate=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('****Results****')\n",
    "prediction = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, prediction)\n",
    "print(\"Accuracy: {:.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {}\n",
    "for feature, importance in zip(X_train.columns, clf.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Feature-importance'})\n",
    "importances.sort_values(by='Feature-importance').plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futureData = pd.DataFrame(columns=['category', 'main_category', 'currency', 'deadline', 'goal', 'launched', 'country', 'usd_goal_real'])\n",
    "futureData.loc[0] = ['Restaurants', 'Food', 'USD', '2019-07-30', '60000.0', '2019-04-01 12:00:00','US', '60000.00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futureData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futureData['country'] = countryTransformer.transform(futureData['country'])\n",
    "futureData['currency'] = currencyTransformer.transform(futureData['currency'])\n",
    "futureData['main_category'] = main_categoryTransformer.transform(futureData['main_category'])\n",
    "futureData['category'] = categoryTransformer.transform(futureData['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futureData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futureData[\"launched\"] = pd.to_datetime(dataframe[\"launched\"])\n",
    "futureData[\"deadline\"] = pd.to_datetime(dataframe[\"deadline\"])\n",
    "futureData[\"deadline\"] =  futureData.deadline.values.astype(np.int64)\n",
    "futureData[\"launched\"] =  futureData.launched.values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futureData[\"project_length\"] = futureData[\"deadline\"] - futureData[\"launched\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(futureData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
